{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2485d7a9-8094-4152-9cac-edfa54a0cfc7",
   "metadata": {},
   "source": [
    "**Collect() Operation with RDD Operation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d546791f-b239-4ef8-9e70-2ace55040e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a92864f-d152-46b5-9ce7-e6ef7e758929",
   "metadata": {},
   "outputs": [],
   "source": [
    " header = data.first()\n",
    " rows = data.filter(lambda line: line != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6b0be74-ab51-47c6-95be-f3ce5b788e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_rdd = rows.map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f50936-c368-4f42-a9a2-f539569575aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Student Dataset (first 10 rows) ===\n",
      "['1', 'Alice', '20', 'F', '66', '92', '44']\n",
      "['2', 'Bob', '20', 'M', '82', '52', '77']\n",
      "['3', 'Charlie', '22', 'F', '43', '57', '76']\n",
      "['4', 'David', '19', 'M', '95', '69', '46']\n",
      "['5', 'Eva', '19', 'F', '62', '44', '96']\n",
      "['6', 'Frank', '22', 'F', '70', '78', '94']\n",
      "['7', 'Grace', '24', 'F', '67', '66', '93']\n",
      "['8', 'Henry', '21', 'F', '53', '82', '60']\n",
      "['9', 'Ivy', '19', 'M', '64', '52', '46']\n",
      "['10', 'Jack', '19', 'F', '44', '59', '60']\n"
     ]
    }
   ],
   "source": [
    " print(\"=== Student Dataset (first 10 rows) ===\")\n",
    " for row in split_rdd.take(10):   # you can change 10 → 20, 50 etc.\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46cbb462-b8ca-48e9-8037-5efe4edcd4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_rdd = split_rdd.map(lambda x: (int(x[0]), x[1], int(x[2]), x[3], int(x[4]), int(x[5]), int(x[6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1d4e0c-7e85-42e3-921c-ba1cc7913878",
   "metadata": {},
   "outputs": [],
   "source": [
    " avg_marks_rdd = students_rdd.map(lambda x: (x[1], (x[4] + x[5] + x[6]) / 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ba70f2-aeef-4b9c-88ec-e0ced1bea280",
   "metadata": {},
   "outputs": [],
   "source": [
    " passed_rdd = avg_marks_rdd.filter(lambda x: x[1] >= 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cd2368-cf91-4747-b4de-31b47b15f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_passed_rdd = passed_rdd.sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c99bed-86c8-4a3f-ae40-a61792618b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    " results = sorted_passed_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "531e2561-93db-408c-8680-527556852c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Students with Average >= 75 ===\n",
      "Name: Leo, Avg Marks: 88.00\n",
      "Name: Olivia, Avg Marks: 88.00\n",
      "Name: Rita, Avg Marks: 86.67\n",
      "Name: Kathy, Avg Marks: 81.67\n",
      "Name: George, Avg Marks: 81.67\n",
      "Name: Frank, Avg Marks: 80.67\n",
      "Name: Oscar, Avg Marks: 80.00\n",
      "Name: Uma, Avg Marks: 78.33\n",
      "Name: Kyle, Avg Marks: 78.33\n",
      "Name: Matt, Avg Marks: 78.33\n",
      "Name: Tina, Avg Marks: 76.00\n",
      "Name: Victor, Avg Marks: 75.67\n",
      "Name: Grace, Avg Marks: 75.33\n",
      "Name: Mona, Avg Marks: 75.00\n",
      "Name: Will, Avg Marks: 75.00\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Students with Average >= 75 ===\")\n",
    "for student in results:\n",
    "    print(f\"Name: {student[0]}, Avg Marks: {student[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d2319b-f306-4489-8a35-c4ccd10e4d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of students who passed: 15\n"
     ]
    }
   ],
   "source": [
    " count_passed = passed_rdd.count()\n",
    " print(\"\\nNumber of students who passed:\", count_passed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb294c5b-22ae-435d-b304-861a8b6f5f8a",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "This PySpark RDD program demonstrates how to process and analyze a student dataset using distributed data operations. The analysis successfully loads the CSV file, removes the header, splits the data into structured fields, and calculates each student’s average marks. Using transformations like map(), filter(), and sortBy(), the program identifies students who scored an average of 75 or above. The collect() operation retrieves the processed results from all worker nodes to the driver for display. The output shows that 15 students passed, with Olivia being the top scorer. Overall, this experiment clearly shows how PySpark’s RDD operations can efficiently handle data transformation, filtering, sorting, and aggregation in a parallel computing environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
