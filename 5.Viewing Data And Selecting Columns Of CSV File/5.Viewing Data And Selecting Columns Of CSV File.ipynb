{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e6c1a9-cb95-419d-b9eb-fb0add7f949a",
   "metadata": {},
   "source": [
    "**Viewing Data And Selecting Columns Of CSV File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe8ab803-d578-4154-931a-cd130e00c684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-2P70OJO0:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f08953-5b39-4c70-9704-f117f1d9d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    " from pyspark.sql import SparkSession\n",
    " spark = SparkSession.builder.appName(\"SamplingExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c80b16-2dfa-46ab-b694-c84de061a185",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = spark.read.csv(\"students.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaa44c12-b5b0-46af-9c67-3e9297992e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First 5 rows of dataset ===\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "| id|   name|age|gender|math|science|english|\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "|  1|  Alice| 20|     F|  66|     92|     44|\n",
      "|  2|    Bob| 20|     M|  82|     52|     77|\n",
      "|  3|Charlie| 22|     F|  43|     57|     76|\n",
      "|  4|  David| 19|     M|  95|     69|     46|\n",
      "|  5|    Eva| 19|     F|  62|     44|     96|\n",
      "+---+-------+---+------+----+-------+-------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"=== First 5 rows of dataset ===\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e058e1-8536-4534-a6fc-e7b602a8fb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Schema of dataset ===\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- math: integer (nullable = true)\n",
      " |-- science: integer (nullable = true)\n",
      " |-- english: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    " print(\"=== Schema of dataset ===\")\n",
    " df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6996d6-b138-46b9-8546-92efdbfe2f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample (30% without replacement) ===\n",
      "+---+------+---+------+----+-------+-------+\n",
      "| id|  name|age|gender|math|science|english|\n",
      "+---+------+---+------+----+-------+-------+\n",
      "|  4| David| 19|     M|  95|     69|     46|\n",
      "|  8| Henry| 21|     F|  53|     82|     60|\n",
      "| 17|Quincy| 18|     M|  65|     79|     54|\n",
      "| 19|   Sam| 18|     F|  76|     70|     65|\n",
      "| 27| Aaron| 25|     F|  81|     99|     44|\n",
      "| 28| Bella| 19|     F|  54|     76|     76|\n",
      "| 32| Fiona| 22|     F|  48|     96|     48|\n",
      "| 37|  Kyle| 21|     M|  57|     86|     92|\n",
      "| 39|  Matt| 25|     M|  64|     71|    100|\n",
      "| 41| Oscar| 20|     M|  87|     72|     81|\n",
      "+---+------+---+------+----+-------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    " print(\"=== Sample (30% without replacement) ===\")\n",
    " df.sample(withReplacement=False, fraction=0.3, seed=42).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52b4601b-908c-40ad-bc88-ae0aabf24d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample (20% with replacement) ===\n",
      "+---+------+---+------+----+-------+-------+\n",
      "| id|  name|age|gender|math|science|english|\n",
      "+---+------+---+------+----+-------+-------+\n",
      "|  6| Frank| 22|     F|  70|     78|     94|\n",
      "|  7| Grace| 24|     F|  67|     66|     93|\n",
      "| 14|Nathan| 23|     F|  71|     66|     60|\n",
      "| 17|Quincy| 18|     M|  65|     79|     54|\n",
      "| 21|   Uma| 19|     F|  89|     70|     76|\n",
      "| 22|Victor| 22|     M|  96|     75|     56|\n",
      "| 31| Ethan| 24|     M|  53|     57|     45|\n",
      "| 32| Fiona| 22|     F|  48|     96|     48|\n",
      "| 35|   Ian| 21|     F|  72|     75|     70|\n",
      "| 38| Laura| 23|     M|  84|     73|     56|\n",
      "+---+------+---+------+----+-------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    " print(\"=== Sample (20% with replacement) ===\")\n",
    " df.sample(withReplacement=True, fraction=0.2, seed=42).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1953f8d-6c19-497d-9324-f9c38540fc75",
   "metadata": {},
   "source": [
    "print(\"=== takeSample: 5 rows (without replacement) ===\")\n",
    "sampled_rows = df.rdd.takeSample(False, 5, seed=42)\n",
    "for row in sampled_rows:\n",
    " print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "049f05e8-adab-4630-bc5b-3d0902f01753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== takeSample: 5 rows (with replacement) ===\n",
      "Row(id=47, name='Umar', age=21, gender='F', math=75, science=80, english=59)\n",
      "Row(id=17, name='Quincy', age=18, gender='M', math=65, science=79, english=54)\n",
      "Row(id=10, name='Jack', age=19, gender='F', math=44, science=59, english=60)\n",
      "Row(id=38, name='Laura', age=23, gender='M', math=84, science=73, english=56)\n",
      "Row(id=23, name='Wendy', age=24, gender='M', math=57, science=83, english=81)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== takeSample: 5 rows (with replacement) ===\")\n",
    "sampled_rows_wr = df.rdd.takeSample(True, 5, seed=42)\n",
    "for row in sampled_rows_wr:\n",
    " print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d6ce70-e261-4331-84b9-574285ffbf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 50\n"
     ]
    }
   ],
   "source": [
    " print(\"Total rows in dataset:\", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f4dfac-ef76-4726-8b53-df21cbf3dc64",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "In this PySpark program, dataset sampling was successfully implemented and demonstrated using both the sample() and takeSample() methods. The sample() function allowed random selection of data either with or without replacement, providing flexibility in how subsets are drawn from the full dataset. Similarly, the takeSample() method was used to directly retrieve a specific number of random rows from the DataFrameâ€™s RDD. Through these operations, we can easily analyze portions of large datasets without loading all data into memory. Overall, this experiment shows how sampling in PySpark helps in quick testing, model training, and exploratory data analysis efficiently on big data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
